import collections
import numpy

from django import db

from openquake.engine.calculators.hazard.event_based.core \
    import RuptureData, EventBasedHazardCalculator as EBHC

from openquake.engine.db import models
from openquake.engine.utils import tasks
from openquake.engine.performance import EnginePerformanceMonitor

from openquake.hazardlib.imt import from_string
from openquake.commonlib.general import split_in_blocks
from openquake.commonlib.logictree import SourceModelLogicTree, GSIM

from openquake.risklib import scientific

from openquake.engine import logs

from openquake.engine.calculators.risk.event_based import core
from openquake.engine.calculators.risk import writers


class AssetSiteAssociationError(Exception):
    pass


@tasks.oqtask
def event_based_fr(job_id, rupture_data, rc, risk_models, assocs,
                   outputdict, params):
    """
    :param int job_id:
        ID of the currently running job
    :param sids:
        numpy array of site IDs
    :param rupture_data:
        a list with the rupture data generated by the parent task
    :param int task_no:
        the number of the task that generated the rupture_data
    """
    hc = rc.hazard_calculation
    correl_model = hc.get_correl_model()
    truncation_level = hc.truncation_level
    imts = map(from_string, sorted(hc.intensity_measure_types))
    # NB: by construction rupture_data is a non-empty list with
    # ruptures of homogeneous trt_model
    trt_model = rupture_data[0].rupture.trt_model

    getters = []
    gmv_dict = dict((str(imt), collections.defaultdict(dict)) for imt in imts)
    for gsim_name, rlzs in trt_model.get_rlzs_by_gsim().iteritems():
        gsim = GSIM[gsim_name]()
        for rlz in rlzs:
            gmf = models.Gmf.objects.filter(lt_realization=rlz).latest('id')
            getter = GmfGetter(gmf, epsilons=[], site_ids=[], assets=[],
                               rupture_ids=[], gmv_dict=gmv_dict.copy())
            for rdata in rupture_data:
                for _gsim_name, imt, site_id, rupid, gmv in rdata.calc_gmf(
                        imts, [gsim], truncation_level, correl_model):
                    getter.gmv_dict[str(imt)][site_id][rupid] = gmv
                    getter.rupture_ids.append(rupid)
                    getters.append(getter)

    monitor = EnginePerformanceMonitor(
        None, job_id, event_based_fr, tracing=True)
    elt = {}  # event loss table
    for taxonomy, risk_model in risk_models.iteritems():
        with db.transaction.commit_on_success(using='job_init'):
            assets, site_ids = assocs[taxonomy]
            with monitor.copy('building epsilons'):
                epsilons = scientific.make_epsilons(
                    numpy.zeros((len(assets), len(getters[0].rupture_ids))),
                    rc.master_seed, rc.asset_correlation)
            for getter in getters:
                getter.site_ids = site_ids
                getter.assets = assets
                getter.epsilons = epsilons

            elt.update(
                core.do_event_based(
                    risk_model, getters, outputdict, params, monitor))
    return elt


def assoc_assets_sites(rc, taxonomy):
    """
    Return two lists asset_ids, site_ids
    """
    cursor = models.getcursor('job_init')
    query = '''\
SELECT exp.id AS asset_id, hsite.id AS site_id
FROM riski.exposure_data AS exp
JOIN hzrdi.hazard_site AS hsite
ON exp.site::TEXT=hsite.location::TEXT
WHERE hsite.hazard_calculation_id = %s
AND exposure_model_id = %s AND taxonomy=%s
AND ST_COVERS(ST_GeographyFromText(%s), exp.site)'''
    args = (rc.hazard_calculation.id, rc.exposure_model.id, taxonomy,
            rc.region_constraint.wkt)
    # print cursor.mogrify(query, args) useful when debugging
    cursor.execute(query, args)
    assets_sites = cursor.fetchall()
    if not assets_sites:
        raise AssetSiteAssociationError(
            'Could not associated any asset of taxonomy %s' % taxonomy)
    return zip(*assets_sites)  # asset_ids, site_ids


class EventBasedFRRiskCalculator(core.EventBasedRiskCalculator):

    @EnginePerformanceMonitor.monitor
    def execute(self):
        """
        Method responsible for the distribution strategy. It divides
        the considered exposure into chunks of homogeneous assets
        (i.e. having the same taxonomy).
        """
        # create a Gmf output for each realization
        self.hcalc = EBHC(self.hc.oqjob)
        self.hcalc.source_model_lt = SourceModelLogicTree.from_hc(self.hc)
        self.hcalc.initialize_realizations()
        # can we avoid to create the Gmf objects altogether?
        # the outputs probably needs to be there
        for rlz in self.hcalc._get_realizations():
            output = models.Output.objects.create(
                oq_job=self.job,
                display_name='GMF rlz-%s' % rlz.id,
                output_type='gmf')
            models.Gmf.objects.create(output=output, lt_realization=rlz)
        self.generate_gmfs()

    @EnginePerformanceMonitor.monitor
    def generate_gmfs(self):
        """
        Generate the GMFs and optionally the hazard curves too
        """
        otm = tasks.OqTaskManager(event_based_fr, logs.LOG.progress)
        rupture_data = []
        for rupture in models.ProbabilisticRupture.objects.filter(
                trt_model__lt_model__hazard_calculation=self.hc
                ).order_by('trt_model'):
            rdata = RuptureData(
                self.hc.site_collection, rupture,
                [(r.id, r.seed) for r in rupture.sesrupture_set.all()])
            rupture_data.append(rdata)

        assocs = {}
        with self.monitor('associating assets<->sites'):
            for taxonomy in self.risk_models:
                logs.LOG.info('associating assets<->sites for taxonomy %s',
                              taxonomy)
                try:
                    asset_ids, site_ids = assoc_assets_sites(self.rc, taxonomy)
                except AssetSiteAssociationError as e:
                    logs.LOG.warn(str(e))
                    continue
                assets = models.ExposureData.objects.get_asset_chunk(
                    self.rc, taxonomy, asset_ids=asset_ids)
                assocs[taxonomy] = assets, site_ids

        outputdict = writers.combine_builders(
            [ob(self) for ob in self.output_builders])
        for rblock in split_in_blocks(
                rupture_data, self.concurrent_tasks,
                RuptureData.get_weight, RuptureData.get_trt):
            otm.submit(self.job.id, rblock, self.rc, self.risk_models,
                       assocs, outputdict, self.calculator_parameters)
        self.acc = otm.aggregate_results(self.agg_result, {})


class GmfGetter(object):
    """
    Hazard getter for computing ground motion values from ruptures
    """
    def __init__(self, gmf, epsilons, site_ids, assets, rupture_ids, gmv_dict):
        self.hid = gmf.id
        self.weight = gmf.lt_realization.weight
        self.site_ids = site_ids
        self.assets = assets
        self.rupture_ids = rupture_ids
        self.gmv_dict = gmv_dict
        self.epsilons = epsilons

    def get_epsilons(self):
        return self.epsilons

    def get_data(self, imt):
        """
        Extracts the GMFs for the given `imt` from the hazard output.

        :param str imt: Intensity Measure Type
        :returns: a list of N arrays with R elements each.
        """
        gmv_dict = self.gmv_dict[imt]
        all_gmvs = []
        for site_id in self.site_ids:
            gmv = gmv_dict.get(site_id, {})
            if not gmv:
                logs.LOG.info('No data for site_id=%d, imt=%s', site_id, imt)
            array = numpy.array([gmv.get(r, 0.) for r in self.rupture_ids])
            all_gmvs.append(array)
        return all_gmvs
